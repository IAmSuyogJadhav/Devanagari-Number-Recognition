{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "np.random.seed(7)\n",
    "tf.set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 1296) (2304, 10) \n",
      " (576, 1296) (576, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('E:\\Machine Learning\\PycharmProjects\\Devanagari Numerals Recognition\\data_normalized.npy')\n",
    "labels_orig = np.load('E:\\Machine Learning\\PycharmProjects\\Devanagari Numerals Recognition\\labels.npy')\n",
    "\n",
    "idx = np.random.permutation(len(data))\n",
    "data, labels_orig = data[idx], labels_orig[idx]\n",
    "\n",
    "labels = (np.arange(10) == labels_orig).astype(int)\n",
    "m, n = data.shape\n",
    "\n",
    "train = data[:int(0.8*m), :]\n",
    "train_labels = labels[:int(0.8*m), :].reshape(int(0.8*m), 10)\n",
    "test = data[int(0.8*m):, :]\n",
    "test_labels = labels[int(0.8*m):, :].reshape(m - int(0.8*m), 10)\n",
    "print(train.shape, train_labels.shape, '\\n', test.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession()\n",
    "import keras\n",
    "from keras.models import Sequential, model_from_json\n",
    "import keras.layers as ll\n",
    "\n",
    "model = Sequential(name=\"ForwardProp\")\n",
    "model.add(ll.InputLayer([1296]))\n",
    "\n",
    "model.add(ll.Dense(40, activation='relu'))\n",
    "model.add(ll.Dense(30, activation='sigmoid'))\n",
    "model.add(ll.Dense(20, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.add(ll.Dense(10, activation='softmax', kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                51880     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 53,940\n",
      "Trainable params: 53,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 576 samples\n",
      "Epoch 1/50\n",
      "2304/2304 [==============================] - 1s 572us/step - loss: 2.5926 - acc: 0.3859 - val_loss: 2.3864 - val_acc: 0.7396\n",
      "Epoch 2/50\n",
      "2304/2304 [==============================] - 0s 134us/step - loss: 2.2230 - acc: 0.8025 - val_loss: 2.1104 - val_acc: 0.8073\n",
      "Epoch 3/50\n",
      "2304/2304 [==============================] - 0s 186us/step - loss: 1.9735 - acc: 0.8433 - val_loss: 1.9079 - val_acc: 0.8194\n",
      "Epoch 4/50\n",
      "2304/2304 [==============================] - 0s 187us/step - loss: 1.7789 - acc: 0.8811 - val_loss: 1.7457 - val_acc: 0.8455\n",
      "Epoch 5/50\n",
      "2304/2304 [==============================] - 0s 180us/step - loss: 1.6221 - acc: 0.9093 - val_loss: 1.6187 - val_acc: 0.8646\n",
      "Epoch 6/50\n",
      "2304/2304 [==============================] - 0s 142us/step - loss: 1.4923 - acc: 0.9431 - val_loss: 1.5145 - val_acc: 0.8785\n",
      "Epoch 7/50\n",
      "2304/2304 [==============================] - 0s 140us/step - loss: 1.3847 - acc: 0.9579 - val_loss: 1.4294 - val_acc: 0.8941\n",
      "Epoch 8/50\n",
      "2304/2304 [==============================] - 0s 128us/step - loss: 1.2970 - acc: 0.9701 - val_loss: 1.3606 - val_acc: 0.9028\n",
      "Epoch 9/50\n",
      "2304/2304 [==============================] - 0s 129us/step - loss: 1.2242 - acc: 0.9813 - val_loss: 1.2999 - val_acc: 0.9201\n",
      "Epoch 10/50\n",
      "2304/2304 [==============================] - 0s 138us/step - loss: 1.1657 - acc: 0.9874 - val_loss: 1.2630 - val_acc: 0.9184\n",
      "Epoch 11/50\n",
      "2304/2304 [==============================] - 0s 134us/step - loss: 1.1180 - acc: 0.9896 - val_loss: 1.2258 - val_acc: 0.9288\n",
      "Epoch 12/50\n",
      "2304/2304 [==============================] - 0s 135us/step - loss: 1.0800 - acc: 0.9948 - val_loss: 1.1943 - val_acc: 0.9340\n",
      "Epoch 13/50\n",
      "2304/2304 [==============================] - 0s 138us/step - loss: 1.0500 - acc: 0.9957 - val_loss: 1.1770 - val_acc: 0.9306\n",
      "Epoch 14/50\n",
      "2304/2304 [==============================] - 0s 142us/step - loss: 1.0255 - acc: 0.9970 - val_loss: 1.1540 - val_acc: 0.9358\n",
      "Epoch 15/50\n",
      "2304/2304 [==============================] - 0s 153us/step - loss: 1.0059 - acc: 0.9974 - val_loss: 1.1398 - val_acc: 0.9340\n",
      "Epoch 16/50\n",
      "2304/2304 [==============================] - 0s 202us/step - loss: 0.9884 - acc: 0.9983 - val_loss: 1.1288 - val_acc: 0.9358\n",
      "Epoch 17/50\n",
      "2304/2304 [==============================] - 0s 176us/step - loss: 0.9735 - acc: 0.9983 - val_loss: 1.1198 - val_acc: 0.9323\n",
      "Epoch 18/50\n",
      "2304/2304 [==============================] - 0s 154us/step - loss: 0.9598 - acc: 0.9991 - val_loss: 1.1079 - val_acc: 0.9340\n",
      "Epoch 19/50\n",
      "2304/2304 [==============================] - 0s 148us/step - loss: 0.9475 - acc: 0.9991 - val_loss: 1.0999 - val_acc: 0.9340\n",
      "Epoch 20/50\n",
      "2304/2304 [==============================] - 0s 181us/step - loss: 0.9364 - acc: 0.9991 - val_loss: 1.0878 - val_acc: 0.9340\n",
      "Epoch 21/50\n",
      "2304/2304 [==============================] - 0s 178us/step - loss: 0.9257 - acc: 0.9991 - val_loss: 1.0810 - val_acc: 0.9375\n",
      "Epoch 22/50\n",
      "2304/2304 [==============================] - 0s 190us/step - loss: 0.9159 - acc: 0.9991 - val_loss: 1.0700 - val_acc: 0.9340\n",
      "Epoch 23/50\n",
      "2304/2304 [==============================] - 0s 205us/step - loss: 0.9065 - acc: 0.9991 - val_loss: 1.0625 - val_acc: 0.9358\n",
      "Epoch 24/50\n",
      "2304/2304 [==============================] - 0s 180us/step - loss: 0.8973 - acc: 0.9991 - val_loss: 1.0540 - val_acc: 0.9358\n",
      "Epoch 25/50\n",
      "2304/2304 [==============================] - 0s 186us/step - loss: 0.8882 - acc: 0.9991 - val_loss: 1.0456 - val_acc: 0.9392\n",
      "Epoch 26/50\n",
      "2304/2304 [==============================] - 0s 214us/step - loss: 0.8792 - acc: 0.9996 - val_loss: 1.0361 - val_acc: 0.9410\n",
      "Epoch 27/50\n",
      "2304/2304 [==============================] - 0s 195us/step - loss: 0.8707 - acc: 0.9996 - val_loss: 1.0289 - val_acc: 0.9410\n",
      "Epoch 28/50\n",
      "2304/2304 [==============================] - 0s 212us/step - loss: 0.8624 - acc: 0.9996 - val_loss: 1.0215 - val_acc: 0.9410\n",
      "Epoch 29/50\n",
      "2304/2304 [==============================] - 0s 173us/step - loss: 0.8543 - acc: 0.9996 - val_loss: 1.0129 - val_acc: 0.9410\n",
      "Epoch 30/50\n",
      "2304/2304 [==============================] - 0s 177us/step - loss: 0.8462 - acc: 0.9996 - val_loss: 1.0048 - val_acc: 0.9410\n",
      "Epoch 31/50\n",
      "2304/2304 [==============================] - 0s 152us/step - loss: 0.8374 - acc: 0.9996 - val_loss: 0.9932 - val_acc: 0.9427\n",
      "Epoch 32/50\n",
      "2304/2304 [==============================] - 0s 141us/step - loss: 0.8295 - acc: 1.0000 - val_loss: 0.9883 - val_acc: 0.9427\n",
      "Epoch 33/50\n",
      "2304/2304 [==============================] - 0s 206us/step - loss: 0.8212 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.9392\n",
      "Epoch 34/50\n",
      "2304/2304 [==============================] - 0s 165us/step - loss: 0.8137 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.9375\n",
      "Epoch 35/50\n",
      "2304/2304 [==============================] - 0s 132us/step - loss: 0.8067 - acc: 1.0000 - val_loss: 0.9691 - val_acc: 0.9392\n",
      "Epoch 36/50\n",
      "2304/2304 [==============================] - 0s 122us/step - loss: 0.7999 - acc: 1.0000 - val_loss: 0.9643 - val_acc: 0.9392\n",
      "Epoch 37/50\n",
      "2304/2304 [==============================] - 0s 121us/step - loss: 0.7934 - acc: 1.0000 - val_loss: 0.9590 - val_acc: 0.9392\n",
      "Epoch 38/50\n",
      "2304/2304 [==============================] - 0s 125us/step - loss: 0.7869 - acc: 1.0000 - val_loss: 0.9534 - val_acc: 0.9392\n",
      "Epoch 39/50\n",
      "2304/2304 [==============================] - 0s 124us/step - loss: 0.7809 - acc: 1.0000 - val_loss: 0.9494 - val_acc: 0.9392\n",
      "Epoch 40/50\n",
      "2304/2304 [==============================] - 0s 118us/step - loss: 0.7750 - acc: 1.0000 - val_loss: 0.9435 - val_acc: 0.9375\n",
      "Epoch 41/50\n",
      "2304/2304 [==============================] - 0s 124us/step - loss: 0.7694 - acc: 1.0000 - val_loss: 0.9403 - val_acc: 0.9392\n",
      "Epoch 42/50\n",
      "2304/2304 [==============================] - 0s 125us/step - loss: 0.7639 - acc: 1.0000 - val_loss: 0.9346 - val_acc: 0.9392\n",
      "Epoch 43/50\n",
      "2304/2304 [==============================] - 0s 125us/step - loss: 0.7585 - acc: 1.0000 - val_loss: 0.9285 - val_acc: 0.9392\n",
      "Epoch 44/50\n",
      "2304/2304 [==============================] - 0s 129us/step - loss: 0.7534 - acc: 1.0000 - val_loss: 0.9248 - val_acc: 0.9392\n",
      "Epoch 45/50\n",
      "2304/2304 [==============================] - 0s 123us/step - loss: 0.7489 - acc: 1.0000 - val_loss: 0.9208 - val_acc: 0.9392\n",
      "Epoch 46/50\n",
      "2304/2304 [==============================] - 0s 129us/step - loss: 0.7448 - acc: 1.0000 - val_loss: 0.9170 - val_acc: 0.9375\n",
      "Epoch 47/50\n",
      "2304/2304 [==============================] - 0s 123us/step - loss: 0.7413 - acc: 1.0000 - val_loss: 0.9136 - val_acc: 0.9375\n",
      "Epoch 48/50\n",
      "2304/2304 [==============================] - 0s 130us/step - loss: 0.7380 - acc: 1.0000 - val_loss: 0.9106 - val_acc: 0.9375\n",
      "Epoch 49/50\n",
      "2304/2304 [==============================] - 0s 124us/step - loss: 0.7349 - acc: 1.0000 - val_loss: 0.9079 - val_acc: 0.9375\n",
      "Epoch 50/50\n",
      "2304/2304 [==============================] - 0s 128us/step - loss: 0.7320 - acc: 1.0000 - val_loss: 0.9054 - val_acc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25c8bec4908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_labels, validation_data=(test, test_labels), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 57us/step\n",
      "576/576 [==============================] - 0s 67us/step\n",
      "\n",
      "Loss: 0.9054184556007385\n",
      "Accuracy:0.9375\n",
      "576/576 [==============================] - 0s 73us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.90541845560073853, 0.9375]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nLoss: {}\\nAccuracy:{}'.format(model.evaluate(test, test_labels)[0], model.evaluate(test, test_labels)[1]))\n",
    "model.evaluate(test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\Machine Learning\\PycharmProjects\\Devanagari Numerals Recognition\\model %0.2f%%.json' % (100*model.evaluate(test, test_labels)[1]), 'w') as model_json:\n",
    "    model_json.write(model.to_json())\n",
    "model.save_weights('E:\\Machine Learning\\PycharmProjects\\Devanagari Numerals Recognition\\weights %0.2f%%.h5' % (100*model.evaluate(test, test_labels)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
